{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Data was obtained from a [Kaggle competition](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
    "\n",
    "Let's organize the data into:\n",
    "- Training Data\n",
    "- Validation Data\n",
    "- Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mall_images\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory to the dogs and cats directories\n",
    "# os.chdir('data/dogs-cats-data/')\n",
    "# If the the train/dogs diretory does not exist then proceed to create some directories\n",
    "if os.path.isdir('train/dog') is False:\n",
    "    os.makedirs('train/dog')\n",
    "    os.makedirs('train/cat')\n",
    "    os.makedirs('valid/dog')\n",
    "    os.makedirs('valid/cat')\n",
    "    os.makedirs('test/dog')\n",
    "    os.makedirs('test/cat')\n",
    "    \n",
    "    for e in random.sample(glob.glob('all_images/cat*'), 500):\n",
    "        shutil.move(e,'train/cat')\n",
    "    for e in random.sample(glob.glob('all_images/dog*'), 500):\n",
    "        shutil.move(e,'train/dog')\n",
    "    for e in random.sample(glob.glob('all_images/cat*'), 100):\n",
    "        shutil.move(e,'valid/cat')\n",
    "    for e in random.sample(glob.glob('all_images/dog*'), 100):\n",
    "        shutil.move(e,'valid/dog')\n",
    "    for e in random.sample(glob.glob('all_images/cat*'), 50):\n",
    "        shutil.move(e,'test/cat')\n",
    "    for e in random.sample(glob.glob('all_images/dog*'), 50):\n",
    "        shutil.move(e,'test/dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('../../')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolution_neural_animals.ipynb \u001b[1m\u001b[36mdata\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/dogs-cats-data/train/'\n",
    "valid_path = 'data/dogs-cats-data/valid/'\n",
    "test_path = 'data/dogs-cats-data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# The images are passsed to the prerpocessing function before they get passed to the network\n",
    "# target_size: it is the height and width of what we want the images to be resized to\n",
    "\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = train_path, target_size = (224,224), classes = ['cat', 'dog'], batch_size = 10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = valid_path, target_size = (224,224), classes = ['cat', 'dog'], batch_size = 10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = test_path, target_size = (224,224), classes = ['cat', 'dog'], batch_size = 10, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_batches.n == 1000\n",
    "assert valid_batches.n == 200\n",
    "assert test_batches.n == 100\n",
    "assert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    \"\"\"\n",
    "    A function that plots images in the form of a grid with 1 row and 10 columns where images\n",
    "    are placed\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1,10, figsize = (20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
